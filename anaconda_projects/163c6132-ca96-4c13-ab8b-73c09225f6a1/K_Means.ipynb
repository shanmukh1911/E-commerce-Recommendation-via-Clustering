{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a025bd0d-d3d9-4421-b71e-cd918f97a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify paths to your saved files\n",
    "synthetic_dataset_path = \"C:\\Projects\\E-Commerce\\synthetic_dataset.csv\"\n",
    "synthetic_customers_path = \"C:\\Projects\\E-Commerce\\synthetic_customers.csv\"\n",
    "\n",
    "# Load datasets\n",
    "df_transactions = pd.read_csv(synthetic_dataset_path)\n",
    "df_customers = pd.read_csv(synthetic_customers_path)\n",
    "\n",
    "# Inspect first few rows\n",
    "print(\"Transactions Data:\")\n",
    "display(df_transactions.head())\n",
    "\n",
    "print(\"Customer Summary:\")\n",
    "display(df_customers.head())\n",
    "# -------------------------------\n",
    "#Ensure RFM Table is Correct\n",
    "# -------------------------------\n",
    "# Convert date column to datetime\n",
    "df_transactions['date'] = pd.to_datetime(df_transactions['date'])\n",
    "\n",
    "# Snapshot date = day after last transaction\n",
    "snapshot_date = df_transactions['date'].max() + pd.Timedelta(days=1)\n",
    "\n",
    "# Compute RFM\n",
    "rfm = df_transactions.groupby('customer_id').agg({\n",
    "    'date': lambda x: (snapshot_date - x.max()).days,  # Recency\n",
    "    'transaction_id': 'nunique',                       # Frequency\n",
    "    'total_amount': 'sum'                              # Monetary\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns\n",
    "rfm.rename(columns={'date':'Recency','transaction_id':'Frequency','total_amount':'Monetary'}, inplace=True)\n",
    "\n",
    "display(rfm.head())\n",
    "# -------------------------------\n",
    "# Scaling\n",
    "# --------------------------------\n",
    "# Example: scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "rfm_log = rfm.copy()\n",
    "rfm_log['Recency'] = np.log1p(rfm_log['Recency'])\n",
    "rfm_log['Frequency'] = np.log1p(rfm_log['Frequency'])\n",
    "rfm_log['Monetary'] = np.log1p(rfm_log['Monetary'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "rfm_scaled = scaler.fit_transform(rfm_log[['Recency','Frequency','Monetary']])\n",
    "\n",
    "# -------------------------------\n",
    "# K-Means from Scratch on RFM Data\n",
    "# -------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Step 0: Load your RFM table ---\n",
    "# Assume rfm is your DataFrame with columns ['Recency', 'Frequency', 'Monetary']\n",
    "# rfm = pd.read_csv(\"rfm_table.csv\")  # if needed\n",
    "\n",
    "# --- Step 1: Log-transform skewed features ---\n",
    "rfm_log = rfm.copy()\n",
    "rfm_log['Recency'] = np.log1p(rfm_log['Recency'])\n",
    "rfm_log['Frequency'] = np.log1p(rfm_log['Frequency'])\n",
    "rfm_log['Monetary'] = np.log1p(rfm_log['Monetary'])\n",
    "\n",
    "# --- Step 2: Standardize features ---\n",
    "scaler = StandardScaler()\n",
    "rfm_scaled = scaler.fit_transform(rfm_log[['Recency','Frequency','Monetary']])\n",
    "\n",
    "# --- Step 3: K-Means function ---\n",
    "def kmeans_scratch(X, K, max_iters=100, tol=1e-4, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    n_samples, n_features = X.shape\n",
    "    # Initialize centroids randomly\n",
    "    centroids = X[np.random.choice(n_samples, K, replace=False)]\n",
    "    \n",
    "    for iteration in range(max_iters):\n",
    "        # Compute distances to centroids\n",
    "        distances = np.linalg.norm(X[:, np.newaxis] - centroids, axis=2)  # (n_samples, K)\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "        \n",
    "        # Update centroids\n",
    "        new_centroids = np.array([\n",
    "            X[labels == k].mean(axis=0) if np.any(labels==k) else centroids[k]\n",
    "            for k in range(K)\n",
    "        ])\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.all(np.linalg.norm(new_centroids - centroids, axis=1) < tol):\n",
    "            break\n",
    "        \n",
    "        centroids = new_centroids\n",
    "    \n",
    "    # Compute final loss (sum of squared distances)\n",
    "    loss = sum(np.sum((X[labels == k] - centroids[k])**2) for k in range(K))\n",
    "    \n",
    "    return labels, centroids, loss\n",
    "\n",
    "# --- Step 4: Elbow Method ---\n",
    "losses = []\n",
    "K_range = range(1, 11)\n",
    "for k in K_range:\n",
    "    _, _, loss = kmeans_scratch(rfm_scaled, K=k)\n",
    "    losses.append(loss)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(K_range, losses, 'bo-', markersize=8)\n",
    "plt.xlabel(\"Number of clusters (K)\")\n",
    "plt.ylabel(\"Sum of squared distances (Loss)\")\n",
    "plt.title(\"Elbow Method for Optimal K\")\n",
    "plt.show()\n",
    "\n",
    "# --- Step 5: Run K-Means with chosen K ---\n",
    "optimal_K = 4  # choose based on elbow\n",
    "labels, centroids, final_loss = kmeans_scratch(rfm_scaled, K=optimal_K)\n",
    "\n",
    "# Assign clusters to original RFM table\n",
    "rfm['Cluster'] = labels\n",
    "\n",
    "# --- Step 6: Transform centroids back to original scale ---\n",
    "centroids_unscaled = centroids * rfm_log[['Recency','Frequency','Monetary']].std().values + \\\n",
    "                     rfm_log[['Recency','Frequency','Monetary']].mean().values\n",
    "\n",
    "print(\"Centroids (original scale):\")\n",
    "print(pd.DataFrame(centroids_unscaled, columns=['Recency','Frequency','Monetary']))\n",
    "\n",
    "# --- Step 7: Summary per cluster ---\n",
    "cluster_summary = rfm.groupby('Cluster')[['Recency','Frequency','Monetary']].mean()\n",
    "cluster_summary['Size'] = rfm.groupby('Cluster').size()\n",
    "display(cluster_summary)\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "# Use the scaled RFM features for plotting\n",
    "x = rfm_scaled[:,0]  # Recency (scaled)\n",
    "y = rfm_scaled[:,1]  # Frequency (scaled)\n",
    "z = rfm_scaled[:,2]  # Monetary (scaled)\n",
    "clusters = rfm['Cluster'].values\n",
    "\n",
    "# Create 3D scatter plot\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot points\n",
    "scatter = ax.scatter(x, y, z, c=clusters, cmap='tab10', s=60)\n",
    "\n",
    "# Add labels\n",
    "ax.set_xlabel('Recency (scaled)')\n",
    "ax.set_ylabel('Frequency (scaled)')\n",
    "ax.set_zlabel('Monetary (scaled)')\n",
    "ax.set_title('3D Scatter Plot of RFM Clusters')\n",
    "\n",
    "# Add legend\n",
    "legend1 = ax.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2176224a-8ece-4881-b957-216b925a838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- Assume rfm_scaled is already prepared ---\n",
    "# rfm_scaled: standardized & log-transformed RFM features\n",
    "\n",
    "# Step 1: Compute K vs Loss\n",
    "losses = []\n",
    "K_range = range(1, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    labels, centroids, loss = kmeans_scratch(rfm_scaled, K=k)\n",
    "    losses.append(loss)\n",
    "\n",
    "# Step 2: Create table\n",
    "k_loss_table = pd.DataFrame({\n",
    "    \"K\": K_range,\n",
    "    \"Sum_of_Squared_Distances\": losses\n",
    "})\n",
    "\n",
    "print(\"K vs Loss Table:\")\n",
    "display(k_loss_table)\n",
    "\n",
    "# Step 3: Plot elbow curve\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(K_range, losses, 'bo-', markersize=8)\n",
    "plt.xlabel(\"Number of clusters (K)\")\n",
    "plt.ylabel(\"Sum of squared distances (Loss)\")\n",
    "plt.title(\"Elbow Method\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Optional - compute derivative (loss reduction per cluster)\n",
    "k_loss_table['Loss_Reduction'] = k_loss_table['Sum_of_Squared_Distances'].diff(-1).fillna(0)\n",
    "print(\"K vs Loss vs Loss Reduction:\")\n",
    "display(k_loss_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2057e741-7fe2-4a46-8105-39bebc5e15ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Assume rfm DataFrame is ready ---\n",
    "# rfm columns: ['customer_id','Recency','Frequency','Monetary']\n",
    "\n",
    "# --- Step 0: Log + Scale ---\n",
    "rfm_log = rfm.copy()\n",
    "rfm_log['Recency'] = np.log1p(rfm_log['Recency'])\n",
    "rfm_log['Frequency'] = np.log1p(rfm_log['Frequency'])\n",
    "rfm_log['Monetary'] = np.log1p(rfm_log['Monetary'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "rfm_scaled = scaler.fit_transform(rfm_log[['Recency','Frequency','Monetary']])\n",
    "\n",
    "# --- Step 1: K-Means from scratch ---\n",
    "def kmeans_scratch(X, K, max_iters=100, tol=1e-4, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    n_samples, n_features = X.shape\n",
    "    centroids = X[np.random.choice(n_samples, K, replace=False)]\n",
    "    \n",
    "    for iteration in range(max_iters):\n",
    "        distances = np.linalg.norm(X[:, np.newaxis] - centroids, axis=2)\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "        \n",
    "        new_centroids = np.array([\n",
    "            X[labels == k].mean(axis=0) if np.any(labels==k) else centroids[k]\n",
    "            for k in range(K)\n",
    "        ])\n",
    "        if np.all(np.linalg.norm(new_centroids - centroids, axis=1) < tol):\n",
    "            break\n",
    "        centroids = new_centroids\n",
    "    \n",
    "    return labels, centroids\n",
    "\n",
    "# --- Step 2: User input for number of clusters ---\n",
    "K_input = int(input(\"Enter number of clusters: \"))\n",
    "\n",
    "labels, centroids = kmeans_scratch(rfm_scaled, K=K_input)\n",
    "rfm['Cluster'] = labels\n",
    "\n",
    "# --- Step 3: Cluster summary table ---\n",
    "cluster_summary = rfm.groupby('Cluster')[['Recency','Frequency','Monetary']].mean()\n",
    "cluster_summary['Size'] = rfm.groupby('Cluster').size()\n",
    "cluster_summary = cluster_summary.sort_index()\n",
    "print(\"\\nCluster Summary Table:\")\n",
    "display(cluster_summary)\n",
    "\n",
    "# --- Step 4: 3D Scatter plot ---\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = rfm_scaled[:,0]  # Recency\n",
    "y = rfm_scaled[:,1]  # Frequency\n",
    "z = rfm_scaled[:,2]  # Monetary\n",
    "\n",
    "scatter = ax.scatter(x, y, z, c=labels, cmap='tab10', s=60)\n",
    "\n",
    "ax.set_xlabel('Recency (scaled)')\n",
    "ax.set_ylabel('Frequency (scaled)')\n",
    "ax.set_zlabel('Monetary (scaled)')\n",
    "ax.set_title(f'3D Scatter Plot for {K_input} Clusters')\n",
    "\n",
    "legend1 = ax.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1d98b3-4204-4ab5-8f3d-74fc9fff4338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
